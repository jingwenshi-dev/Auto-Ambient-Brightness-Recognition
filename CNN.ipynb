{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## CNN for Ambient Brightness Recognition"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ssV7skh7tmY7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. import packages"
   ],
   "metadata": {
    "collapsed": false,
    "id": "jxEC4357tmY9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "id": "BUdqkQRDtmY-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681513968644,
     "user_tz": 240,
     "elapsed": 1104,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "ExecuteTime": {
     "start_time": "2023-04-30T01:11:19.137360Z",
     "end_time": "2023-04-30T01:11:22.127522Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nvidia GPU: True\n",
      "Current Device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nvidia GPU: {torch.backends.mps.is_available()}\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Current Device: {device}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JioNcY4ctmZA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363957,
     "user_tz": 240,
     "elapsed": 10,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "outputId": "ae798593-bd9c-4e7d-cfbc-df82988ade6b",
    "ExecuteTime": {
     "start_time": "2023-04-30T01:11:22.115114Z",
     "end_time": "2023-04-30T01:11:22.137550Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "EMk0h6n_tmZC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#load date to train, valid and test\n",
    "train_path = \"./Train\"\n",
    "valid_path = \"./Valid\"\n",
    "test_path = \"./Test\""
   ],
   "metadata": {
    "id": "rftk2t7XtmZC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363958,
     "user_tz": 240,
     "elapsed": 8,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "ExecuteTime": {
     "start_time": "2023-04-30T01:11:22.138584Z",
     "end_time": "2023-04-30T01:11:22.139993Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# def compress_images(path, target_size=(640, 480)):\n",
    "#     for root, dirs, files in os.walk(path):\n",
    "#         for file in files:\n",
    "#             if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "#                 img_path = os.path.join(root, file)\n",
    "#                 try:\n",
    "#                     img = Image.open(img_path)\n",
    "#                     img = img.resize(target_size, Image.ANTIALIAS)\n",
    "#                     img.save(img_path)\n",
    "#                     print(f\"Successfully compressed {img_path}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error compressing {img_path}: {e}\")\n",
    "#\n",
    "# compress_images(train_path)\n",
    "# compress_images(valid_path)\n",
    "# compress_images(test_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T01:11:22.141974Z",
     "end_time": "2023-04-30T01:11:22.143196Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1260\n",
      "    Root location: ./Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 418\n",
      "    Root location: ./Valid\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 414\n",
      "    Root location: ./Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageFolder(train_path, transform=transforms.ToTensor())\n",
    "print(train_data)\n",
    "valid_data = ImageFolder(valid_path, transform=transforms.ToTensor())\n",
    "print(valid_data)\n",
    "test_data = ImageFolder(test_path, transform=transforms.ToTensor())\n",
    "print(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T01:11:22.144749Z",
     "end_time": "2023-04-30T01:11:22.174951Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Shape of the data\n",
    "\n",
    "for x, y in train_data:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    break\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "\n",
    "for x, y in train_loader:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    break\n",
    "\n",
    "print(\"Num of Img in Training Set:\", len(train_data))\n",
    "print(\"Num of Img in Test Set:\", len(test_data))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTqu4OzAOkeA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512363958,
     "user_tz": 240,
     "elapsed": 8,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "outputId": "5d967d94-4d29-403d-dc8f-69417c9685a7",
    "ExecuteTime": {
     "start_time": "2023-04-30T01:11:22.152633Z",
     "end_time": "2023-04-30T01:11:22.224562Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 480, 640])\n",
      "0\n",
      "torch.Size([10, 3, 480, 640])\n",
      "tensor([1, 0, 3, 3, 0, 3, 3, 3, 3, 0])\n",
      "Num of Img in Training Set: 1260\n",
      "Num of Img in Test Set: 414\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.CNN Model"
   ],
   "metadata": {
    "id": "vtca_mHSb866"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, out_channels) -> None:\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Level 1: (0 + 24) / 2 = 12\n",
    "        # Level 2: (25 + 49) / 2 = 37\n",
    "        # Level 3: (50 + 74) / 2 = 62\n",
    "        # Level 4: (75 + 100) / 2 = 87\n",
    "        self.brightness_levels = 4\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=self.out_channels, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "        self.out_channels *= 2\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.out_channels//2, out_channels=self.out_channels, kernel_size=3, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "        self.out_channels *= 2\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=self.out_channels//2, out_channels=self.out_channels, kernel_size=3, padding=1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "        # A size of 640x480 picture is reduced by a factor of 2 three times in three pooling layers -> 80x60.\n",
    "        self.fc = nn.Linear(self.out_channels * 80 * 60, self.brightness_levels)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.batch_norm1(self.pool(torch.relu(self.conv1(x))))\n",
    "        x = self.batch_norm2(self.pool(torch.relu(self.conv2(x))))\n",
    "        x = self.batch_norm3(self.pool(torch.relu(self.conv3(x))))\n",
    "\n",
    "        # Resize the input from 4D to 3D wrt to the batch size in order to fit the input size of FC layer\n",
    "        x = x.view(-1, self.out_channels * 80 * 60)\n",
    "\n",
    "        return torch.softmax(self.fc(x), dim=1)"
   ],
   "metadata": {
    "id": "6AIlML3JvwBl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681512368530,
     "user_tz": 240,
     "elapsed": 9,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "ExecuteTime": {
     "start_time": "2023-04-30T01:11:22.777674Z",
     "end_time": "2023-04-30T01:11:22.780214Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Training"
   ],
   "metadata": {
    "id": "nOexSTt6X7mp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_accuracy(model, data, batch_size=32):\n",
    "    # note: why should we use a larger batch size here?\n",
    "    loader = DataLoader(data, batch_size=batch_size)\n",
    "\n",
    "    model.eval() # annotate model for evaluation (why do we need to do this?)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Loader returns images and corresponding labels in a batch\n",
    "    # imgs = a batch of imgs at current iteration\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        output = model(imgs)\n",
    "\n",
    "        # output.max(1, keepdim=True) returns the index of highest prob in softmax\n",
    "        _, pred = output.max(1, keepdim=True)\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "\n",
    "    return correct/total"
   ],
   "metadata": {
    "id": "tMeHGP3BX9Dp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681514011142,
     "user_tz": 240,
     "elapsed": 393,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "ExecuteTime": {
     "start_time": "2023-04-30T01:11:23.840670Z",
     "end_time": "2023-04-30T01:11:23.856100Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, train_data, valid_data, batch_size=64, weight_decay=0.0,\n",
    "          optimizer=\"sgd\", momentum=0.9, learning_rate=0.001, num_epochs=7,\n",
    "          shuffle_data=True, checkpoint_path=None, print_acc=True):\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle_data, drop_last=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    assert optimizer in (\"sgd\", \"adam\")\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(),\n",
    "                              lr=learning_rate,\n",
    "                              weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.Adam(model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               weight_decay=weight_decay)\n",
    "\n",
    "    iters, losses, train_acc, val_acc, n = [], [], [], [], 0\n",
    "\n",
    "    print(\"\\n ----- Start Training ----- \\n\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(train_loader):\n",
    "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            # Start training mode\n",
    "            model.train()\n",
    "\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            n += 1\n",
    "\n",
    "        iters.append(n)\n",
    "        losses.append(float(loss)/batch_size)\n",
    "        train_acc.append(get_accuracy(model, train_data, batch_size))\n",
    "        val_acc.append(get_accuracy(model, valid_data, batch_size))\n",
    "\n",
    "        if checkpoint_path is not None:\n",
    "            weight_path = checkpoint_path + f'Weight{epoch}.ckpt'\n",
    "            torch.save(model.state_dict(), weight_path)\n",
    "\n",
    "        if print_acc:\n",
    "            print(\"Iter %d. [Val Acc %.0f%%] [Train Acc %.0f%%, Loss %f]\" % (\n",
    "                    n, val_acc[-1] * 100, train_acc[-1] * 100, losses[-1]))\n",
    "\n",
    "    # Plot Graph\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "44gN6N5GaDs5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1681513980812,
     "user_tz": 240,
     "elapsed": 2303,
     "user": {
      "displayName": "Jingwen Shi",
      "userId": "14606256671433276260"
     }
    },
    "outputId": "3b376413-018d-48b6-b263-f9f62614857a",
    "ExecuteTime": {
     "start_time": "2023-04-30T01:11:24.407976Z",
     "end_time": "2023-04-30T01:11:24.409805Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Start Training ----- \n",
      "\n",
      "Iter 19. [Val Acc 37%] [Train Acc 22%, Loss 0.015113]\n",
      "Iter 38. [Val Acc 44%] [Train Acc 43%, Loss 0.021469]\n",
      "Iter 57. [Val Acc 26%] [Train Acc 28%, Loss 0.020960]\n",
      "Iter 76. [Val Acc 59%] [Train Acc 53%, Loss 0.010198]\n",
      "Iter 95. [Val Acc 36%] [Train Acc 47%, Loss 0.017309]\n",
      "Iter 114. [Val Acc 60%] [Train Acc 35%, Loss 0.019007]\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "out_channels = 32\n",
    "\n",
    "model = CNN(out_channels)\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint_path = 'checkpoint/'\n",
    "\n",
    "train(model, train_data, valid_data, batch_size=64,\n",
    "      optimizer=\"adam\", momentum=0.9, learning_rate=0.0008, num_epochs=30,\n",
    "      shuffle_data=True, checkpoint_path=checkpoint_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T23:58:40.004322Z",
     "end_time": "2023-04-30T00:04:51.478611Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "1el2s1Rgy7FX24o_rO1Hg9vIeck_plia0",
     "timestamp": 1680570556286
    }
   ],
   "toc_visible": true
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
